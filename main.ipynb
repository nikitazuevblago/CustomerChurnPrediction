{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['JAVA_HOME'] = 'C:\\\\Program Files\\\\Java\\\\jdk-11'\n",
    "os.environ['PATH'] = os.environ['JAVA_HOME'] + '\\\\bin;' + os.environ['PATH']\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler, StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import IndexToString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Churn Prediction\").config(\"spark.memory.offHeap.enabled\",\"true\").config(\"spark.memory.offHeap.size\",\"10g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerID: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- SeniorCitizen: string (nullable = true)\n",
      " |-- Partner: string (nullable = true)\n",
      " |-- Dependents: string (nullable = true)\n",
      " |-- tenure: string (nullable = true)\n",
      " |-- PhoneService: string (nullable = true)\n",
      " |-- MultipleLines: string (nullable = true)\n",
      " |-- InternetService: string (nullable = true)\n",
      " |-- OnlineSecurity: string (nullable = true)\n",
      " |-- OnlineBackup: string (nullable = true)\n",
      " |-- DeviceProtection: string (nullable = true)\n",
      " |-- TechSupport: string (nullable = true)\n",
      " |-- StreamingTV: string (nullable = true)\n",
      " |-- StreamingMovies: string (nullable = true)\n",
      " |-- Contract: string (nullable = true)\n",
      " |-- PaperlessBilling: string (nullable = true)\n",
      " |-- PaymentMethod: string (nullable = true)\n",
      " |-- MonthlyCharges: string (nullable = true)\n",
      " |-- TotalCharges: string (nullable = true)\n",
      " |-- Churn: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_path = r'data\\WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
    "df = spark.read.csv(df_path,header=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
      "|customerID|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|   MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|       PaymentMethod|MonthlyCharges|TotalCharges|Churn|\n",
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
      "|7590-VHVEG|Female|            0|    Yes|        No|     1|          No|No phone service|            DSL|            No|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|         29.85|       29.85|   No|\n",
      "|5575-GNVDE|  Male|            0|     No|        No|    34|         Yes|              No|            DSL|           Yes|          No|             Yes|         No|         No|             No|      One year|              No|        Mailed check|         56.95|      1889.5|   No|\n",
      "|3668-QPYBK|  Male|            0|     No|        No|     2|         Yes|              No|            DSL|           Yes|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|        Mailed check|         53.85|      108.15|  Yes|\n",
      "|7795-CFOCW|  Male|            0|     No|        No|    45|          No|No phone service|            DSL|           Yes|          No|             Yes|        Yes|         No|             No|      One year|              No|Bank transfer (au...|          42.3|     1840.75|   No|\n",
      "|9237-HQITU|Female|            0|     No|        No|     2|         Yes|              No|    Fiber optic|            No|          No|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|          70.7|      151.65|  Yes|\n",
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerID: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- SeniorCitizen: string (nullable = true)\n",
      " |-- Partner: string (nullable = true)\n",
      " |-- Dependents: string (nullable = true)\n",
      " |-- tenure: float (nullable = true)\n",
      " |-- PhoneService: string (nullable = true)\n",
      " |-- MultipleLines: string (nullable = true)\n",
      " |-- InternetService: string (nullable = true)\n",
      " |-- OnlineSecurity: string (nullable = true)\n",
      " |-- OnlineBackup: string (nullable = true)\n",
      " |-- DeviceProtection: string (nullable = true)\n",
      " |-- TechSupport: string (nullable = true)\n",
      " |-- StreamingTV: string (nullable = true)\n",
      " |-- StreamingMovies: string (nullable = true)\n",
      " |-- Contract: string (nullable = true)\n",
      " |-- PaperlessBilling: string (nullable = true)\n",
      " |-- PaymentMethod: string (nullable = true)\n",
      " |-- MonthlyCharges: float (nullable = true)\n",
      " |-- TotalCharges: float (nullable = true)\n",
      " |-- Churn: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change certain types to numeric\n",
    "to_numeric = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "for col in to_numeric:\n",
    "    df = df.withColumn(col, F.col(col).cast(FloatType()))\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for null_values\n",
      "Column 'TotalCharges' has 11 null values\n",
      "\n",
      "Checking for outliers\n",
      "Column 'TotalCharges' has 5 outliers\n"
     ]
    }
   ],
   "source": [
    "# Delete ID as it is unnecessary\n",
    "df = df.drop('CustomerID')\n",
    "\n",
    "# Check for null values and outliers\n",
    "print('\\nChecking for null_values')\n",
    "for col in df.columns:\n",
    "    null_count = df.filter(F.col(col).isNull()).count()\n",
    "    if null_count>0:\n",
    "        print(f\"Column '{col}' has {null_count} null values\")\n",
    "        first_value_type = type(df.select(col).first()[0])\n",
    "\n",
    "        if first_value_type==str:\n",
    "            most_frequent_value = df.groupby(col).count().orderBy('count',ascending=False).first()[0]\n",
    "            df = df.fillna({col: most_frequent_value})\n",
    "        else:\n",
    "            avg_value = df.agg(F.avg('TotalCharges')).collect()[0][0]\n",
    "            df = df.fillna({col: avg_value})\n",
    "\n",
    "print('\\nChecking for outliers')\n",
    "for col in df.columns:\n",
    "    first_value_type = type(df.select(col).first()[0])\n",
    "\n",
    "    if first_value_type!=str:    \n",
    "        quantiles = df.approxQuantile(col, [0.25,0.75],0.01)\n",
    "        Q1 = quantiles[0]\n",
    "        Q3 = quantiles[1]\n",
    "        IQR = Q3-Q1\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        outliers = df.filter((F.col(col) < lower_bound) | (F.col(col) > upper_bound))\n",
    "        if outliers.count()>0:\n",
    "            print(f\"Column '{col}' has {outliers.count()} outliers\")\n",
    "            df = df.filter((F.col(col) >= lower_bound) & (F.col(col) <= upper_bound))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|scaled_feature_vector|\n",
      "+---------------------+\n",
      "| (30,[0,1,2,4,6,11...|\n",
      "| (30,[0,1,2,3,4,5,...|\n",
      "| [0.08148068183113...|\n",
      "| (30,[0,1,2,3,4,5,...|\n",
      "| (30,[0,1,2,4,5,6,...|\n",
      "+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelCol = 'Churn'\n",
    "\n",
    "# Convert categorical data to numeric representation\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col+'_indexed') for col in df.columns if col not in to_numeric and col!=labelCol]\n",
    "\n",
    "# Perform OneHotEncoding to numerical categorical data\n",
    "encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=indexer.getOutputCol() + '_encoded') for indexer in indexers]\n",
    "\n",
    "# Assemble columns in feature vector col\n",
    "assembler = VectorAssembler(inputCols=to_numeric+[encoder.getOutputCol() for encoder in encoders], outputCol='feature_vector')\n",
    "\n",
    "# Standardize feature vector col\n",
    "scaler = StandardScaler(inputCol='feature_vector', outputCol='scaled_feature_vector')\n",
    "\n",
    "# Create data preparation pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler])\n",
    "\n",
    "# Fit to data and transform\n",
    "model = pipeline.fit(df)\n",
    "final_df = model.transform(df)\n",
    "\n",
    "# Transforming labelCol to integer col\n",
    "label_indexer = StringIndexer(inputCol=\"Churn\", outputCol=\"label\").fit(final_df)\n",
    "final_df = label_indexer.transform(final_df)\n",
    "\n",
    "# Convert the label column from double (float) to integer\n",
    "final_df = final_df.withColumn(\"label\", F.col(\"label\").cast(\"int\"))\n",
    "\n",
    "final_df.select('scaled_feature_vector').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5032 2006\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = final_df.randomSplit([0.7, 0.3], seed=42)\n",
    "print(train_df.count(), test_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(featuresCol='scaled_feature_vector', labelCol='label', maxIter=200, maxDepth=10)\n",
    "model = gbt.fit(train_df)\n",
    "predictions = model.transform(test_df)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert predicted values back to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+\n",
      "|Churn|prediction_label|\n",
      "+-----+----------------+\n",
      "|   No|             Yes|\n",
      "|   No|              No|\n",
      "|  Yes|             Yes|\n",
      "|   No|              No|\n",
      "|  Yes|             Yes|\n",
      "+-----+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_converter = IndexToString(inputCol='prediction',outputCol='prediction_label', labels=label_indexer.labels)\n",
    "\n",
    "# Apply the label_converter to the predictions DataFrame\n",
    "predictions_with_labels = label_converter.transform(predictions)\n",
    "predictions_with_labels.select('Churn','prediction_label').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8671497584541062\n",
      "Precision: 0.8635428935859286\n",
      "Recall: 0.8671497584541062\n",
      "F1 Score: 0.8640254859261522\n",
      "AUC: 0.9335931643189354\n"
     ]
    }
   ],
   "source": [
    "evaluator_multi = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_multi.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "precision = evaluator_multi.evaluate(predictions, {evaluator_multi.metricName: \"weightedPrecision\"})\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = evaluator_multi.evaluate(predictions, {evaluator_multi.metricName: \"weightedRecall\"})\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1 = evaluator_multi.evaluate(predictions, {evaluator_multi.metricName: \"f1\"})\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Evaluate the model using BinaryClassificationEvaluator for AUC\n",
    "evaluator_auc = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator_auc.evaluate(predictions)\n",
    "print(f\"AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
